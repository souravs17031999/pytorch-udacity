{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRANSFER_LEARNING_NEW_FINAL",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "O8anqU1Xi8Ro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# google colab does not come with torch installed. And also, in course we are using torch 0.4. \n",
        "# so following snippet of code installs the relevant version\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16v5QpiyjFr8",
        "colab_type": "code",
        "outputId": "a27f8fd4-31e7-42a4-9f4b-b71609c4de2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "# \n",
        "# if it prints otherwise, then you need to enable GPU: \n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aiSFBlQajILl",
        "colab_type": "code",
        "outputId": "d8e58696-4747-4cdd-ad93-225fe76a2e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "# this should print 5.3.0. If it doesn't, then restart your runtime:\n",
        "# Menu > Runtime > Restart Runtime"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Utb0jEsqjPbt",
        "colab_type": "code",
        "outputId": "57c07e53-d157-4141-afd9-7df19f804f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "# we will download the cats and dogs dataset and unzip them\n",
        "# after this run, set your data_dir variable: data_dir = 'Cat_Dog_data'\n",
        "# so all the data is available. so path to your training data becomes `Cat_Dog_data/train`\n",
        "# path to test is `Cat_Dog_data/test`\n",
        "\n",
        "!wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
        "\n",
        "# remove existing directories\n",
        "!rm -r Cat_Dog_data __MACOSX || true\n",
        "!unzip -qq Cat_Dog_data.zip"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-29 06:46:36--  https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.101.109\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.101.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uzDgcP0vjP_T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is the contents of helper.py \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ws2PfnTGiw1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BuZqL8KWiw1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets , transforms , models\n",
        "\n",
        "data_dir = 'Cat_Dog_data'\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),transforms.RandomResizedCrop(224),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),transforms.CenterCrop(224),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + '/train' , transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZmBa7axMiw12",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## TODO: Use a pretrained model to classify the cat and dog images\n",
        "#here we are using resnet and so it has two parts \"features\" and \"fc\" whereas we had features and classifer\n",
        "## Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#using pre-trained resnet50 from imageNet database\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "## Freeze parameters so we don't backprop through them\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#creating our own classifier with name fc (as defined in resnet50)\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 512),nn.ReLU(),nn.Dropout(0.2),nn.Linear(512, 2),nn.LogSoftmax(dim=1))    \n",
        "\n",
        "#using crossentropyloss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#taking steps of gradient descent with lr =0.003 and only fc parameters ,Only train the classifier parameters, feature parameters are frozen\n",
        "\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
        "\n",
        "model.to(device);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S0tcje56UIqS",
        "colab_type": "code",
        "outputId": "e98d3871-d4f0-4ab3-df64-14f6535ae5b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1249
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 5\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    \n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    # Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1.. Train loss: 2.023.. Test loss: 0.476.. Test accuracy: 0.757\n",
            "Epoch 1/1.. Train loss: 0.433.. Test loss: 0.157.. Test accuracy: 0.937\n",
            "Epoch 1/1.. Train loss: 0.276.. Test loss: 0.077.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.219.. Test loss: 0.084.. Test accuracy: 0.971\n",
            "Epoch 1/1.. Train loss: 0.245.. Test loss: 0.103.. Test accuracy: 0.958\n",
            "Epoch 1/1.. Train loss: 0.245.. Test loss: 0.072.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.238.. Test loss: 0.065.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.144.. Test loss: 0.068.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.150.. Test loss: 0.068.. Test accuracy: 0.977\n",
            "Epoch 1/1.. Train loss: 0.190.. Test loss: 0.062.. Test accuracy: 0.977\n",
            "Epoch 1/1.. Train loss: 0.131.. Test loss: 0.062.. Test accuracy: 0.979\n",
            "Epoch 1/1.. Train loss: 0.137.. Test loss: 0.061.. Test accuracy: 0.978\n",
            "Epoch 1/1.. Train loss: 0.143.. Test loss: 0.058.. Test accuracy: 0.979\n",
            "Epoch 1/1.. Train loss: 0.196.. Test loss: 0.081.. Test accuracy: 0.968\n",
            "Epoch 1/1.. Train loss: 0.254.. Test loss: 0.054.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.165.. Test loss: 0.053.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.140.. Test loss: 0.051.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.122.. Test loss: 0.052.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.159.. Test loss: 0.095.. Test accuracy: 0.962\n",
            "Epoch 1/1.. Train loss: 0.200.. Test loss: 0.049.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.122.. Test loss: 0.047.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.150.. Test loss: 0.047.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.121.. Test loss: 0.066.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.212.. Test loss: 0.079.. Test accuracy: 0.969\n",
            "Epoch 1/1.. Train loss: 0.231.. Test loss: 0.087.. Test accuracy: 0.967\n",
            "Epoch 1/1.. Train loss: 0.226.. Test loss: 0.056.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.174.. Test loss: 0.061.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.180.. Test loss: 0.055.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.148.. Test loss: 0.048.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.115.. Test loss: 0.046.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.225.. Test loss: 0.054.. Test accuracy: 0.979\n",
            "Epoch 1/1.. Train loss: 0.173.. Test loss: 0.070.. Test accuracy: 0.972\n",
            "Epoch 1/1.. Train loss: 0.235.. Test loss: 0.086.. Test accuracy: 0.966\n",
            "Epoch 1/1.. Train loss: 0.188.. Test loss: 0.053.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.171.. Test loss: 0.050.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.139.. Test loss: 0.043.. Test accuracy: 0.986\n",
            "Epoch 1/1.. Train loss: 0.132.. Test loss: 0.042.. Test accuracy: 0.985\n",
            "Epoch 1/1.. Train loss: 0.168.. Test loss: 0.053.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.138.. Test loss: 0.041.. Test accuracy: 0.986\n",
            "Epoch 1/1.. Train loss: 0.147.. Test loss: 0.044.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.143.. Test loss: 0.046.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.167.. Test loss: 0.044.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.179.. Test loss: 0.055.. Test accuracy: 0.979\n",
            "Epoch 1/1.. Train loss: 0.180.. Test loss: 0.047.. Test accuracy: 0.983\n",
            "Epoch 1/1.. Train loss: 0.145.. Test loss: 0.050.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.198.. Test loss: 0.042.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.173.. Test loss: 0.068.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.179.. Test loss: 0.063.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.117.. Test loss: 0.053.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.159.. Test loss: 0.078.. Test accuracy: 0.967\n",
            "Epoch 1/1.. Train loss: 0.171.. Test loss: 0.051.. Test accuracy: 0.981\n",
            "Epoch 1/1.. Train loss: 0.181.. Test loss: 0.039.. Test accuracy: 0.987\n",
            "Epoch 1/1.. Train loss: 0.106.. Test loss: 0.040.. Test accuracy: 0.986\n",
            "Epoch 1/1.. Train loss: 0.138.. Test loss: 0.049.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.131.. Test loss: 0.042.. Test accuracy: 0.984\n",
            "Epoch 1/1.. Train loss: 0.156.. Test loss: 0.063.. Test accuracy: 0.976\n",
            "Epoch 1/1.. Train loss: 0.236.. Test loss: 0.050.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.129.. Test loss: 0.054.. Test accuracy: 0.979\n",
            "Epoch 1/1.. Train loss: 0.170.. Test loss: 0.067.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.265.. Test loss: 0.130.. Test accuracy: 0.950\n",
            "Epoch 1/1.. Train loss: 0.289.. Test loss: 0.101.. Test accuracy: 0.957\n",
            "Epoch 1/1.. Train loss: 0.247.. Test loss: 0.065.. Test accuracy: 0.975\n",
            "Epoch 1/1.. Train loss: 0.136.. Test loss: 0.062.. Test accuracy: 0.976\n",
            "Epoch 1/1.. Train loss: 0.157.. Test loss: 0.059.. Test accuracy: 0.978\n",
            "Epoch 1/1.. Train loss: 0.125.. Test loss: 0.078.. Test accuracy: 0.969\n",
            "Epoch 1/1.. Train loss: 0.129.. Test loss: 0.045.. Test accuracy: 0.982\n",
            "Epoch 1/1.. Train loss: 0.194.. Test loss: 0.065.. Test accuracy: 0.973\n",
            "Epoch 1/1.. Train loss: 0.238.. Test loss: 0.051.. Test accuracy: 0.980\n",
            "Epoch 1/1.. Train loss: 0.207.. Test loss: 0.068.. Test accuracy: 0.971\n",
            "Epoch 1/1.. Train loss: 0.194.. Test loss: 0.047.. Test accuracy: 0.986\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}