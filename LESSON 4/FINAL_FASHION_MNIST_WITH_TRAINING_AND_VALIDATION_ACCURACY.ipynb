{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_FASHION_MNIST_WITH_TRAINING_AND_VALIDATION_ACCURACY",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rZFoBK4AIAyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlflMzNEIJQK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6sN5E4eILaU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "2d156890-8c13-4571-be43-9a0e98a8823a"
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-26 06:02:52--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a5FFCtGfIPZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "329eccce-1280-4d50-b4cc-1f326f0c5803"
      },
      "cell_type": "code",
      "source": [
        "import helper\n",
        "images, labels = next(iter(trainloader))\n",
        "helper.imshow(images[0,:]);"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNEIOgDRCDoA0Qg6ANEIOgLT/BQw9XWuUKaQLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6dda368588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hses2CPXIQ0L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "luq5s2rjITql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "5eb15862-a522-43a9-edb3-4378cce5d566"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(784,256),nn.ReLU(),nn.Linear(256,10),nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.003)\n",
        "\n",
        "epochs = 30\n",
        "steps = 0\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images , labels in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    images = images.flatten(start_dim=1)\n",
        "  \n",
        "    output = model(images)\n",
        "  \n",
        "    loss = criterion(output,labels)\n",
        "  \n",
        "    loss.backward()\n",
        "  \n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    with torch.no_grad():\n",
        "      for images , labels in testloader:\n",
        "        images = images.flatten(start_dim=1)\n",
        "        log_ps = model(images)\n",
        "        test_loss += criterion(log_ps,labels)\n",
        "        \n",
        "        \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p , top_class = ps.topk(1,dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "    train_losses.append(running_loss/len(trainloader))\n",
        "    test_losses.append(test_loss/len(testloader))    \n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30..  Training Loss: 1.150..  Test Loss: 0.777..  Test Accuracy: 0.741\n",
            "Epoch: 2/30..  Training Loss: 0.683..  Test Loss: 0.645..  Test Accuracy: 0.774\n",
            "Epoch: 3/30..  Training Loss: 0.597..  Test Loss: 0.594..  Test Accuracy: 0.791\n",
            "Epoch: 4/30..  Training Loss: 0.552..  Test Loss: 0.557..  Test Accuracy: 0.804\n",
            "Epoch: 5/30..  Training Loss: 0.523..  Test Loss: 0.537..  Test Accuracy: 0.811\n",
            "Epoch: 6/30..  Training Loss: 0.502..  Test Loss: 0.523..  Test Accuracy: 0.812\n",
            "Epoch: 7/30..  Training Loss: 0.486..  Test Loss: 0.508..  Test Accuracy: 0.818\n",
            "Epoch: 8/30..  Training Loss: 0.473..  Test Loss: 0.499..  Test Accuracy: 0.823\n",
            "Epoch: 9/30..  Training Loss: 0.462..  Test Loss: 0.492..  Test Accuracy: 0.826\n",
            "Epoch: 10/30..  Training Loss: 0.453..  Test Loss: 0.479..  Test Accuracy: 0.830\n",
            "Epoch: 11/30..  Training Loss: 0.445..  Test Loss: 0.474..  Test Accuracy: 0.830\n",
            "Epoch: 12/30..  Training Loss: 0.438..  Test Loss: 0.468..  Test Accuracy: 0.833\n",
            "Epoch: 13/30..  Training Loss: 0.431..  Test Loss: 0.463..  Test Accuracy: 0.835\n",
            "Epoch: 14/30..  Training Loss: 0.425..  Test Loss: 0.461..  Test Accuracy: 0.833\n",
            "Epoch: 15/30..  Training Loss: 0.420..  Test Loss: 0.452..  Test Accuracy: 0.838\n",
            "Epoch: 16/30..  Training Loss: 0.415..  Test Loss: 0.449..  Test Accuracy: 0.841\n",
            "Epoch: 17/30..  Training Loss: 0.410..  Test Loss: 0.442..  Test Accuracy: 0.841\n",
            "Epoch: 18/30..  Training Loss: 0.406..  Test Loss: 0.443..  Test Accuracy: 0.844\n",
            "Epoch: 19/30..  Training Loss: 0.402..  Test Loss: 0.439..  Test Accuracy: 0.843\n",
            "Epoch: 20/30..  Training Loss: 0.398..  Test Loss: 0.432..  Test Accuracy: 0.845\n",
            "Epoch: 21/30..  Training Loss: 0.394..  Test Loss: 0.430..  Test Accuracy: 0.847\n",
            "Epoch: 22/30..  Training Loss: 0.390..  Test Loss: 0.427..  Test Accuracy: 0.844\n",
            "Epoch: 23/30..  Training Loss: 0.387..  Test Loss: 0.424..  Test Accuracy: 0.848\n",
            "Epoch: 24/30..  Training Loss: 0.384..  Test Loss: 0.422..  Test Accuracy: 0.848\n",
            "Epoch: 25/30..  Training Loss: 0.381..  Test Loss: 0.421..  Test Accuracy: 0.848\n",
            "Epoch: 26/30..  Training Loss: 0.378..  Test Loss: 0.418..  Test Accuracy: 0.850\n",
            "Epoch: 27/30..  Training Loss: 0.375..  Test Loss: 0.414..  Test Accuracy: 0.851\n",
            "Epoch: 28/30..  Training Loss: 0.372..  Test Loss: 0.411..  Test Accuracy: 0.853\n",
            "Epoch: 29/30..  Training Loss: 0.370..  Test Loss: 0.410..  Test Accuracy: 0.854\n",
            "Epoch: 30/30..  Training Loss: 0.367..  Test Loss: 0.409..  Test Accuracy: 0.854\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}