{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Xt7cRdj6tnN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c354966d-1418-4be6-ce90-3f64ab3d41a7"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x57abe000 @  0x7fe1c966f2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v2yXhYsst2rh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pA5wkTZZt6yW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ba7cc9bf-d3a5-453c-b873-82253722f1ed"
      },
      "cell_type": "code",
      "source": [
        "### Run this cell\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4UWHrROCuO8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d9bf4d5c-89fb-4504-be9b-80a284c9d83a"
      },
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N1Y1iCGpyKyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "79476017-bec0-4fd7-e817-95a425cfe852"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAHwCAYAAACym4blAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe079090b38>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 249,
              "height": 248
            }
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NCm9doGbwBw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2410
        },
        "outputId": "ce753a20-b268-4f81-ea65-77e90444d155"
      },
      "cell_type": "code",
      "source": [
        "#activation function as sigmoid \n",
        "def activation(x):\n",
        "  return 1/(1+torch.exp(-x))\n",
        "\n",
        "#inputs flattened\n",
        "inputs=images.flatten(start_dim=1)\n",
        "print(f\"the images shape is {inputs.shape}\")\n",
        "#w1 and w2 matrix and bias matrix\n",
        "w1=torch.randn(784,256)\n",
        "print(f\"the w1 shape is {w1.shape}\")\n",
        "b1=torch.randn(256)\n",
        "print(f\"the b1 shape is {b1.shape}\")\n",
        "w2=torch.randn(256,10)\n",
        "print(f\"the w2 shape is {w2.shape}\")\n",
        "b2=torch.randn(10)\n",
        "print(f\"the b2 shape is {b2.shape}\")\n",
        "p=torch.mm(inputs,w1)\n",
        "print(f\"the shape of x*w1 is {p.shape}\")\n",
        "#first output passed to input to\n",
        "h=activation(torch.mm(inputs,w1)+b1)\n",
        "print(f\"the shape of h is {h.shape}\")      \n",
        "o=torch.mm(h,w2)+b2\n",
        "print(f\"the shape of o is o.shape\")\n",
        "print(o)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the images shape is torch.Size([64, 784])\n",
            "the w1 shape is torch.Size([784, 256])\n",
            "the b1 shape is torch.Size([256])\n",
            "the w2 shape is torch.Size([256, 10])\n",
            "the b2 shape is torch.Size([10])\n",
            "the shape of x*w1 is torch.Size([64, 256])\n",
            "the shape of h is torch.Size([64, 256])\n",
            "the shape of o is o.shape\n",
            "tensor([[ -1.4421, -15.4049,   0.1666,   1.5875, -12.7904,  -1.8929, -11.5200,\n",
            "           8.0298, -18.4965,   1.7093],\n",
            "        [  2.5920, -13.5610,   2.5583,   7.5801, -15.3125, -13.9436,  -3.8513,\n",
            "          12.6986, -10.0973,   6.6254],\n",
            "        [  1.4429, -13.3909,  -0.5580,   8.1971,  -9.2776,   1.0251,  -5.3879,\n",
            "           3.6100, -17.2144,   0.5334],\n",
            "        [ -3.4263,  -7.2488,   0.2962,  -4.4456, -14.2005,  -1.1767,  -3.3774,\n",
            "           8.6480,  -5.1414,   5.2002],\n",
            "        [ -2.0947, -18.5011,  -6.3643,   9.6853, -19.9027,  -1.5665, -14.5723,\n",
            "          11.3246, -21.5050,   9.3365],\n",
            "        [ -8.3400, -17.2350,   2.3673,   0.4482, -19.6744, -10.8141, -11.8371,\n",
            "          11.4696, -18.6531,   8.5822],\n",
            "        [ -1.5358, -15.9263,  12.6324,   3.6200, -14.8607,  -3.4144, -12.9942,\n",
            "          11.5133, -12.5764,   7.4593],\n",
            "        [  1.4031,  -7.7447,   7.9810,   3.0554,  -9.1823,   0.6378,   0.8734,\n",
            "          20.6264,  -8.4827,   6.4350],\n",
            "        [ -0.5723,  -3.2669,   3.0849,   9.0674, -17.2599,   3.2915,  -1.3217,\n",
            "           6.7129, -21.6665,   8.9017],\n",
            "        [  0.1280, -16.7350,  -1.5835,   0.0827, -18.7946,  -0.8673, -10.8021,\n",
            "           6.7403, -22.8377,  16.2688],\n",
            "        [  2.1088, -16.1456,   6.0247,   0.4370,  -8.2364,   5.3346, -12.1193,\n",
            "           5.8508,  -9.9554,  20.2313],\n",
            "        [  0.1036, -28.9197,   1.0773,  11.1749,  -6.3934,  -8.8206,  -7.8869,\n",
            "          10.0173, -24.6437,   4.9741],\n",
            "        [  1.0104, -17.9015,   2.6486,   3.5433, -12.5021,  -2.8605,  -6.2663,\n",
            "          13.4027, -15.5461,   2.5422],\n",
            "        [  7.7834,  -9.7769,  -0.7953,   4.1811, -15.2317,   3.8972,  -7.7223,\n",
            "          12.1959, -23.8086,   1.0326],\n",
            "        [  8.7039, -20.5786,   4.1477,   6.5031,  -3.3899,   2.1478,  -3.7649,\n",
            "           4.8477, -28.3720,   1.3173],\n",
            "        [  7.3185, -14.0991,   8.4425,   0.4172, -13.8027,  -2.3280,  -8.4104,\n",
            "          12.8678, -13.8288,  11.9103],\n",
            "        [ -7.3660, -11.6961,   2.5591,  -2.6547, -15.3145,  -7.6153, -19.0260,\n",
            "           8.3246, -15.9535,   4.9197],\n",
            "        [ -9.1499, -15.0422,  -0.9391,  -4.5810,  -4.2774,  -3.9196,  -8.2714,\n",
            "          14.3098,  -9.6300,   4.6608],\n",
            "        [  2.1517, -18.5133,  -2.7526,  16.1027, -16.3637,   1.3182, -16.9309,\n",
            "          12.6196, -20.6040,   4.3803],\n",
            "        [  2.8962,  -5.2919,   1.0904,   9.3375, -16.1318,  -9.4977, -10.3168,\n",
            "           7.2765, -14.7879,   1.3813],\n",
            "        [ -8.2918, -19.3848,   5.3555,  -0.3731,  -6.9306, -15.1595,  -9.9667,\n",
            "           9.1284, -20.9460,   7.4491],\n",
            "        [  1.4146, -15.9893,  -2.7632,  15.1762, -16.1339,   3.6554, -15.3051,\n",
            "          -1.4222, -26.5223,  11.4092],\n",
            "        [  3.6820, -16.5434,  -3.0827,   6.5524,  -9.1907,  -9.6441,  -9.3527,\n",
            "           7.5335, -33.6595,  -0.0080],\n",
            "        [-11.7468,  -9.1914,   8.9795,  -2.7230, -15.9995,  -0.4433,  -7.9473,\n",
            "          -0.3636,  -6.8689,  16.6491],\n",
            "        [  1.0032, -19.3388,   1.4623,   6.3672,  -4.4627,  -5.2510, -14.5494,\n",
            "           0.7038, -16.3289,   2.3186],\n",
            "        [ -3.4501, -12.8447,   7.6696,  -3.4780, -19.4969,  -8.5843, -14.0380,\n",
            "          10.7141, -18.5813,  14.3142],\n",
            "        [-12.4774, -13.0377,   3.3620,  -2.3702, -23.0171,  -7.9541,  -4.7031,\n",
            "          11.8396, -13.7351,   6.9471],\n",
            "        [-13.6967, -14.8801,  -5.8248,   4.7384, -12.8386,   1.6316, -18.5698,\n",
            "          12.9539, -19.8839,   3.0931],\n",
            "        [  5.7578, -14.6575,   7.3748, -11.6311,  -2.7606,  -2.2924,  -9.3177,\n",
            "           0.3945,  -6.2689,  16.6782],\n",
            "        [  5.3036, -13.3965,  10.8009,  -3.5758, -20.6463,  -5.1393, -14.3431,\n",
            "          11.4259, -24.2397,   3.0201],\n",
            "        [  4.2659,   0.7031,  -6.6679,   4.5521, -10.2471,   0.2511,  -8.5709,\n",
            "          11.9530, -18.1472,  -0.3846],\n",
            "        [  2.0838, -16.5031,  -4.8872,   4.3470, -15.7749,   1.4020, -14.1428,\n",
            "           1.5360, -20.3906,  -0.7451],\n",
            "        [ -6.9210,  -6.4400,   4.4121,  -3.4169, -17.4237,  -1.1088,  -8.7379,\n",
            "           8.2446, -13.5967,  16.8714],\n",
            "        [  0.4689, -13.0796,  -2.8258,  -6.5223, -19.3545,   6.5584,  -6.1675,\n",
            "           9.8069, -24.7686,  16.7297],\n",
            "        [ -1.6388,  -4.3413,   0.3694,   5.9068, -17.6298,  -4.0111,  -7.3730,\n",
            "           1.4176, -19.3808,   2.4877],\n",
            "        [  2.5946, -11.8723,  -4.5731,   6.3647, -11.9496,   6.7768,  -5.5110,\n",
            "           5.4459, -13.7665,   5.4529],\n",
            "        [  2.1010, -20.0773,   0.9586,   4.9343, -10.7920,   3.0684,  -6.8900,\n",
            "          12.4564, -14.3194,   0.0520],\n",
            "        [ -3.4013, -10.6841,   9.1060,   3.2987,  -9.0454,  -2.4493,  -7.7205,\n",
            "          13.1534, -23.3887,   0.0529],\n",
            "        [ -6.1869, -14.9629,   1.3836,   8.6155, -12.9969,  -3.5399,  -4.4693,\n",
            "          12.1490, -25.4960,   6.1806],\n",
            "        [ -0.4899, -13.0297,  -7.5318,   6.8901, -17.8185, -10.1070,  -0.9769,\n",
            "           4.6973, -17.6437,   0.2893],\n",
            "        [  7.3401, -11.0243,  -6.0413,   8.2755,  -9.5562,   8.2499,  -8.4596,\n",
            "           7.6603, -21.6573,   2.2583],\n",
            "        [-20.3856, -12.5937,   6.1927,   0.3253, -14.7353, -10.6789, -12.2925,\n",
            "          16.0042, -14.6142,   7.2671],\n",
            "        [-13.4046,  -9.1715,  -2.9012,  -0.4609, -17.7675, -14.2492,   0.7082,\n",
            "          10.7400, -15.7976,   6.9007],\n",
            "        [ -2.3998,  -8.1360,   7.8074,   9.9966, -21.4969,  -0.2194,  -7.6118,\n",
            "          10.6192, -16.7909,   0.7609],\n",
            "        [  0.1661,  -9.9270, -11.4633,   4.8608, -10.7778, -17.2105, -11.7286,\n",
            "          -4.0832,  -7.5609,   1.3420],\n",
            "        [ -6.4095,  -9.6756,  -2.3754,   7.4243, -14.8777, -10.2571, -11.0619,\n",
            "           5.8707, -16.8490,   2.7643],\n",
            "        [ -0.5553,  -9.4834,  -2.5665,   5.8880,  -8.8755,  -3.8775, -17.6563,\n",
            "          14.4911, -23.0080,   0.2232],\n",
            "        [  2.4466, -10.6588,  -2.2265,   7.2463,  -6.2162,   9.3309,  -0.9016,\n",
            "          11.0582, -23.9516,   4.6443],\n",
            "        [ -8.3342, -15.3165,   9.4792,  -7.6254, -18.8472,  -0.7576,  -6.5829,\n",
            "          12.5269, -11.3409,  18.8553],\n",
            "        [  4.4663, -16.4190,  -2.3421,   3.3948, -10.7418,  -3.5364,  -0.1140,\n",
            "           6.5850, -21.1786,   3.1151],\n",
            "        [  4.6673, -10.9601,   3.1470,   6.1092, -13.5443,  -5.7415, -20.8083,\n",
            "           7.8585, -24.3337,   2.9563],\n",
            "        [ -8.4447,  -7.5961,   2.6846,  -3.1326, -11.8044,  -3.8483,  -9.3432,\n",
            "          12.0456, -13.1905,   7.7185],\n",
            "        [-10.9171, -20.7293,  -1.1350,  -6.7103, -13.9921, -14.2924, -15.0785,\n",
            "           9.4110, -25.9705,  10.1964],\n",
            "        [-10.1501,  -8.3430,   0.2031,   6.8356,  -9.1112,  -2.6096,  -8.8647,\n",
            "          -1.9231, -18.3221,   2.0334],\n",
            "        [ -2.2849, -10.5946,  -0.7788,  -6.1591, -11.3216,  -0.7438,  -1.1358,\n",
            "           0.2409,  -4.3762,  11.7266],\n",
            "        [  2.4327,  -7.6472,   5.5082,   2.6431, -11.1428,   5.6372,  -4.6303,\n",
            "           9.5265,  -5.0881,   9.2997],\n",
            "        [ -0.8276, -18.7161,   9.6593,  -6.0862, -12.1125, -14.2816,  -3.3435,\n",
            "          11.6288, -19.8570,  16.6871],\n",
            "        [ 12.7748, -22.9797,   0.3598,  14.7918, -10.9739,   7.9590,  -4.8930,\n",
            "           4.6395, -23.2698,  -5.1747],\n",
            "        [ -3.1729, -18.1695,   1.5761,   3.5945, -10.3139,  -1.2447, -11.1365,\n",
            "           5.5656, -24.4663,   4.1157],\n",
            "        [  2.3969, -20.6202,  -7.4269,  13.5645, -17.5826, -14.7788,  -0.6969,\n",
            "          -6.3052, -23.3728,   6.5724],\n",
            "        [ 10.8623, -14.3745,   9.2242,  -0.4247,  -7.8324,  -5.4494, -15.4654,\n",
            "           2.6077, -12.2217,  14.7363],\n",
            "        [ -2.4353,  -6.2049,  -0.2230,   2.4304, -23.6187,  -7.2027, -12.8856,\n",
            "          10.8496, -14.4072,   0.0046],\n",
            "        [ -0.0053, -13.9406,   9.1328,  10.4892, -20.4892,  -2.3919,  -9.8366,\n",
            "          10.3573, -12.6196,   7.7046],\n",
            "        [ -8.7246, -13.8942,   3.8007,   8.5267, -16.3142,  -2.0597, -10.4660,\n",
            "           4.7098, -20.2349,   9.2690]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7AMSb1DgzRH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2446
        },
        "outputId": "14f1df0e-2275-42d6-84a3-427abdf19c07"
      },
      "cell_type": "code",
      "source": [
        "#softmax function for probability distribution for multi-class\n",
        "def softmax(x):\n",
        "  return torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1) #dimension has to be reshaped when taking sum of tensors because numerator is 64x10 and denominaor will give us 64 so rank 2 and rank 1 can't be operated together and hecne rank -1 is changed to rank -2 by view otherwise broadcasting could get us unexpected output\n",
        "  #also now each one of the value in the  row in numerator gets divided by one of corresponding row value in denominator.\n",
        "probabilities=softmax(o)\n",
        "print(probabilities)\n",
        "print(probabilities.shape)\n",
        "s=torch.sum(probabilities,dim=1) \n",
        "print(s.shape)\n",
        "print(s)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.6686e-05, 6.6180e-11, 3.8312e-04, 1.5864e-03, 9.0401e-10, 4.8853e-05,\n",
            "         3.2206e-09, 9.9611e-01, 3.0065e-12, 1.7919e-03],\n",
            "        [4.0469e-05, 3.9082e-12, 3.9128e-05, 5.9352e-03, 6.7812e-13, 2.6657e-12,\n",
            "         6.4395e-08, 9.9170e-01, 1.2480e-10, 2.2845e-03],\n",
            "        [1.1512e-03, 4.1586e-10, 1.5567e-04, 9.8742e-01, 2.5429e-08, 7.5815e-04,\n",
            "         1.2434e-06, 1.0054e-02, 9.0874e-12, 4.6367e-04],\n",
            "        [5.5270e-06, 1.2089e-07, 2.2864e-04, 1.9943e-06, 1.1569e-10, 5.2418e-05,\n",
            "         5.8041e-06, 9.6888e-01, 9.9456e-07, 3.0825e-02],\n",
            "        [1.1165e-06, 8.3683e-14, 1.5616e-08, 1.4583e-01, 2.0604e-14, 1.8935e-06,\n",
            "         4.2549e-12, 7.5128e-01, 4.1501e-15, 1.0289e-01],\n",
            "        [2.3616e-09, 3.2370e-13, 1.0552e-04, 1.5484e-05, 2.8231e-14, 1.9894e-10,\n",
            "         7.1519e-11, 9.4711e-01, 7.8389e-14, 5.2772e-02],\n",
            "        [5.2745e-07, 2.9681e-13, 7.5056e-01, 9.1478e-05, 8.6149e-13, 8.0600e-08,\n",
            "         5.5705e-12, 2.4510e-01, 8.4592e-12, 4.2533e-03],\n",
            "        [4.4817e-09, 4.7710e-13, 3.2224e-06, 2.3391e-08, 1.1331e-13, 2.0849e-09,\n",
            "         2.6388e-09, 1.0000e+00, 2.2809e-13, 6.8672e-07],\n",
            "        [3.3416e-05, 2.2578e-06, 1.2950e-03, 5.1337e-01, 1.8906e-12, 1.5921e-03,\n",
            "         1.5793e-05, 4.8739e-02, 2.3059e-14, 4.3495e-01],\n",
            "        [9.7748e-08, 4.6410e-15, 1.7653e-08, 9.3423e-08, 5.9176e-16, 3.6131e-08,\n",
            "         1.7508e-12, 7.2749e-05, 1.0382e-17, 9.9993e-01],\n",
            "        [1.3473e-08, 1.5910e-16, 6.7632e-07, 2.5319e-09, 4.3311e-13, 3.3919e-07,\n",
            "         8.9182e-15, 5.6837e-07, 7.7639e-14, 1.0000e+00],\n",
            "        [1.1815e-05, 2.9362e-18, 3.1283e-05, 7.5969e-01, 1.7816e-08, 1.5729e-09,\n",
            "         4.0013e-09, 2.3873e-01, 2.1126e-16, 1.5405e-03],\n",
            "        [4.1498e-06, 2.5392e-14, 2.1356e-05, 5.2250e-05, 5.6186e-12, 8.6486e-08,\n",
            "         2.8694e-09, 9.9990e-01, 2.6769e-13, 1.9199e-05],\n",
            "        [1.1972e-02, 2.8303e-10, 2.2518e-06, 3.2638e-04, 1.2102e-12, 2.4572e-04,\n",
            "         2.2088e-09, 9.8744e-01, 2.2801e-16, 1.4008e-05],\n",
            "        [8.7381e-01, 1.6756e-13, 9.1771e-03, 9.6746e-02, 4.8884e-06, 1.2421e-03,\n",
            "         3.3595e-06, 1.8479e-02, 6.9113e-17, 5.4134e-04],\n",
            "        [2.7794e-03, 1.3880e-12, 8.5525e-03, 2.7972e-06, 1.8669e-12, 1.7969e-07,\n",
            "         4.1019e-10, 7.1443e-01, 1.8188e-12, 2.7424e-01],\n",
            "        [1.4796e-07, 1.9479e-09, 3.0237e-03, 1.6452e-05, 5.2256e-11, 1.1530e-07,\n",
            "         1.2772e-12, 9.6492e-01, 2.7581e-11, 3.2043e-02],\n",
            "        [6.4791e-11, 1.7887e-13, 2.3848e-07, 6.2486e-09, 8.4648e-09, 1.2107e-08,\n",
            "         1.5598e-10, 9.9994e-01, 4.0090e-11, 6.4485e-05],\n",
            "        [8.4723e-07, 8.9812e-16, 6.2821e-09, 9.7019e-01, 7.7072e-15, 3.6815e-07,\n",
            "         4.3708e-15, 2.9797e-02, 1.1101e-16, 7.8681e-06],\n",
            "        [1.4116e-03, 3.9231e-07, 2.3197e-04, 8.8532e-01, 7.6901e-12, 5.8487e-09,\n",
            "         2.5784e-09, 1.1273e-01, 2.9483e-11, 3.1030e-04],\n",
            "        [2.2485e-08, 3.4219e-13, 1.9003e-02, 6.1793e-05, 8.7709e-08, 2.3404e-11,\n",
            "         4.2120e-09, 8.2674e-01, 7.1815e-14, 1.5419e-01],\n",
            "        [1.0315e-06, 2.8513e-14, 1.5815e-08, 9.7739e-01, 2.4674e-14, 9.6971e-06,\n",
            "         5.6520e-14, 6.0459e-08, 7.5968e-19, 2.2598e-02],\n",
            "        [1.5213e-02, 2.5028e-11, 1.7553e-05, 2.6842e-01, 3.9058e-08, 2.4818e-08,\n",
            "         3.3215e-08, 7.1597e-01, 9.2265e-19, 3.7991e-04],\n",
            "        [4.6517e-13, 5.9898e-12, 4.6658e-04, 3.8601e-09, 6.6170e-15, 3.7725e-08,\n",
            "         2.0783e-11, 4.0858e-08, 6.1103e-11, 9.9953e-01],\n",
            "        [4.5326e-03, 6.6360e-12, 7.1732e-03, 9.6802e-01, 1.9166e-05, 8.7128e-06,\n",
            "         7.9789e-10, 3.3596e-03, 1.3462e-10, 1.6889e-02],\n",
            "        [1.8743e-08, 1.5588e-12, 1.2649e-03, 1.8226e-08, 2.0127e-15, 1.1043e-10,\n",
            "         4.7264e-13, 2.6561e-02, 5.0281e-15, 9.7217e-01],\n",
            "        [2.7287e-11, 1.5581e-11, 2.0649e-04, 6.6903e-07, 7.2211e-16, 2.5141e-09,\n",
            "         6.4901e-08, 9.9235e-01, 7.7574e-12, 7.4458e-03],\n",
            "        [2.6646e-12, 8.1594e-13, 6.9881e-09, 2.7033e-04, 6.2850e-12, 1.2096e-05,\n",
            "         2.0382e-14, 9.9967e-01, 5.4770e-15, 5.2160e-05],\n",
            "        [1.8082e-05, 2.4605e-14, 9.1100e-05, 5.0740e-13, 3.6122e-09, 5.7690e-09,\n",
            "         5.1292e-12, 8.4722e-08, 1.0818e-10, 9.9989e-01],\n",
            "        [1.4265e-03, 1.0787e-11, 3.4811e-01, 1.9861e-07, 7.6621e-15, 4.1587e-08,\n",
            "         4.1861e-12, 6.5032e-01, 2.1075e-16, 1.4539e-04],\n",
            "        [4.5816e-04, 1.2993e-05, 8.1760e-09, 6.0999e-04, 2.2809e-10, 8.2685e-06,\n",
            "         1.2192e-09, 9.9891e-01, 8.4555e-14, 4.3786e-06],\n",
            "        [8.5051e-02, 7.2029e-10, 7.9842e-05, 8.1765e-01, 1.4919e-09, 4.3010e-02,\n",
            "         7.6307e-09, 4.9181e-02, 1.4763e-11, 5.0246e-03],\n",
            "        [4.6452e-11, 7.5145e-11, 3.8806e-06, 1.5446e-09, 1.2757e-15, 1.5532e-08,\n",
            "         7.5498e-12, 1.7921e-04, 5.8586e-14, 9.9982e-01],\n",
            "        [8.6615e-08, 1.1312e-13, 3.2117e-09, 7.9680e-11, 2.1300e-16, 3.8214e-05,\n",
            "         1.1361e-10, 9.8411e-04, 9.4856e-19, 9.9898e-01],\n",
            "        [5.0397e-04, 3.3787e-05, 3.7546e-03, 9.5372e-01, 5.7226e-11, 4.7006e-05,\n",
            "         1.6296e-06, 1.0710e-02, 9.9350e-12, 3.1226e-02],\n",
            "        [6.9142e-03, 3.6045e-09, 5.3311e-06, 2.9995e-01, 3.3361e-09, 4.5292e-01,\n",
            "         2.0869e-06, 1.1969e-01, 5.4225e-10, 1.2052e-01],\n",
            "        [3.1798e-05, 7.4213e-15, 1.0145e-05, 5.4060e-04, 7.9992e-11, 8.3666e-05,\n",
            "         3.9599e-09, 9.9933e-01, 2.3503e-12, 4.0979e-06],\n",
            "        [6.3511e-08, 4.3648e-11, 1.7168e-02, 5.1595e-05, 2.2472e-10, 1.6455e-07,\n",
            "         8.4538e-10, 9.8278e-01, 1.3257e-16, 2.0090e-06],\n",
            "        [1.0549e-08, 1.6287e-12, 2.0467e-05, 2.8302e-02, 1.1632e-11, 1.4887e-07,\n",
            "         5.8772e-08, 9.6920e-01, 4.3390e-17, 2.4796e-03],\n",
            "        [5.5978e-04, 2.0047e-09, 4.8952e-07, 8.9770e-01, 1.6684e-11, 3.7272e-08,\n",
            "         3.4397e-04, 1.0018e-01, 1.9870e-11, 1.2202e-03],\n",
            "        [1.3484e-01, 1.4265e-09, 2.0815e-07, 3.4363e-01, 6.1925e-09, 3.3494e-01,\n",
            "         1.8540e-08, 1.8574e-01, 3.4389e-14, 8.3724e-04],\n",
            "        [1.5705e-16, 3.8021e-13, 5.4810e-05, 1.5512e-07, 4.4660e-14, 2.5799e-12,\n",
            "         5.1385e-13, 9.9978e-01, 5.0409e-14, 1.6048e-04],\n",
            "        [3.1979e-11, 2.2043e-09, 1.1653e-06, 1.3374e-05, 4.0748e-13, 1.3743e-11,\n",
            "         4.3051e-05, 9.7889e-01, 2.9215e-12, 2.1056e-02],\n",
            "        [1.3889e-06, 4.4824e-09, 3.7637e-02, 3.3605e-01, 7.0620e-15, 1.2292e-05,\n",
            "         7.5707e-09, 6.2627e-01, 7.8109e-13, 3.2763e-05],\n",
            "        [8.8015e-03, 3.6407e-07, 7.8339e-08, 9.6254e-01, 1.5548e-07, 2.5003e-10,\n",
            "         6.0084e-08, 1.2563e-04, 3.8792e-06, 2.8526e-02],\n",
            "        [8.0410e-07, 3.0683e-08, 4.5427e-05, 8.1899e-01, 1.6890e-10, 1.7152e-08,\n",
            "         7.6704e-09, 1.7321e-01, 2.3524e-11, 7.7530e-03],\n",
            "        [2.9199e-07, 3.8721e-11, 3.9076e-08, 1.8351e-04, 7.1115e-11, 1.0533e-08,\n",
            "         1.0927e-14, 9.9982e-01, 5.1794e-17, 6.3603e-07],\n",
            "        [1.5143e-04, 3.0805e-10, 1.4149e-06, 1.8396e-02, 2.6183e-08, 1.4793e-01,\n",
            "         5.3222e-06, 8.3216e-01, 5.1955e-16, 1.3635e-03],\n",
            "        [1.5520e-12, 1.4406e-15, 8.4568e-05, 3.1532e-12, 4.2187e-17, 3.0297e-09,\n",
            "         8.9433e-12, 1.7816e-03, 7.6756e-14, 9.9813e-01],\n",
            "        [1.0067e-01, 8.5613e-11, 1.1119e-04, 3.4480e-02, 2.5009e-08, 3.3680e-05,\n",
            "         1.0321e-03, 8.3761e-01, 7.3364e-13, 2.6067e-02],\n",
            "        [3.3394e-02, 5.4548e-09, 7.3013e-03, 1.4121e-01, 4.1161e-10, 1.0074e-06,\n",
            "         2.8823e-13, 8.1206e-01, 8.4863e-15, 6.0341e-03],\n",
            "        [1.2457e-09, 2.9106e-09, 8.4883e-05, 2.5262e-07, 4.3285e-11, 1.2349e-07,\n",
            "         5.0723e-10, 9.8688e-01, 1.0823e-11, 1.3032e-02],\n",
            "        [4.6490e-10, 2.5467e-14, 8.2348e-06, 3.1214e-08, 2.1473e-11, 1.5903e-11,\n",
            "         7.2456e-12, 3.1316e-01, 1.3482e-16, 6.8683e-01],\n",
            "        [4.1586e-08, 2.5339e-07, 1.3040e-03, 9.9033e-01, 1.1754e-07, 7.8298e-05,\n",
            "         1.5038e-07, 1.5557e-04, 1.1747e-11, 8.1322e-03],\n",
            "        [8.2199e-07, 2.0231e-10, 3.7063e-06, 1.7074e-08, 9.7783e-11, 3.8382e-06,\n",
            "         2.5937e-06, 1.0276e-05, 1.0153e-07, 9.9998e-01],\n",
            "        [4.5186e-04, 1.8939e-08, 9.7874e-03, 5.5770e-04, 5.7441e-10, 1.1135e-02,\n",
            "         3.8689e-07, 5.4425e-01, 2.4478e-07, 4.3382e-01],\n",
            "        [2.4566e-08, 4.1829e-16, 8.8048e-04, 1.2780e-10, 3.0858e-13, 3.5265e-14,\n",
            "         1.9848e-09, 6.3107e-03, 1.3366e-16, 9.9281e-01],\n",
            "        [1.1732e-01, 3.4784e-17, 4.7598e-07, 8.8170e-01, 5.6943e-12, 9.5031e-04,\n",
            "         2.4908e-09, 3.4373e-05, 2.6023e-17, 1.8793e-09],\n",
            "        [1.1501e-04, 3.5306e-11, 1.3281e-02, 9.9955e-02, 9.1088e-08, 7.9102e-04,\n",
            "         4.0016e-08, 7.1753e-01, 6.5036e-14, 1.6833e-01],\n",
            "        [1.4111e-05, 1.4237e-15, 7.6411e-10, 9.9907e-01, 2.9690e-14, 4.9011e-13,\n",
            "         6.3966e-07, 2.3458e-09, 9.0772e-17, 9.1827e-04],\n",
            "        [2.0272e-02, 2.2217e-13, 3.9397e-03, 2.5410e-07, 1.5413e-10, 1.6703e-09,\n",
            "         7.4632e-14, 5.2717e-06, 1.9128e-12, 9.7578e-01],\n",
            "        [1.6994e-06, 3.9193e-08, 1.5527e-05, 2.2053e-04, 1.0728e-15, 1.4449e-08,\n",
            "         4.9183e-11, 9.9974e-01, 1.0740e-11, 1.9497e-05],\n",
            "        [1.2610e-05, 1.1186e-11, 1.1730e-01, 4.5542e-01, 1.6021e-14, 1.1594e-06,\n",
            "         6.7767e-10, 3.9914e-01, 4.1918e-11, 2.8122e-02],\n",
            "        [1.0283e-08, 5.8473e-11, 2.8298e-03, 3.1933e-01, 5.1999e-12, 8.0655e-06,\n",
            "         1.8023e-09, 7.0242e-03, 1.0310e-13, 6.7080e-01]])\n",
            "torch.Size([64, 10])\n",
            "torch.Size([64])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "viRTvbcmFkEg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}