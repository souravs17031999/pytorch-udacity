{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# TENSORS A USEFUL DATA STRUCTURE IN PyTorch -"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating a numpy array\ndata=np.array([1,2,3])\n\n#creating a tensor from \"Tensor\" constructor and it uses global default datatype as float\ndata1=torch.Tensor(data)\nprint(data1)\nprint(data1.dtype)\n#creating a tensor form \"tensor\" factory function\ndata2=torch.tensor(data)\nprint(data2)\nprint(data2.dtype)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([1., 2., 3.])\ntorch.float32\ntensor([1, 2, 3])\ntorch.int64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(data1.dtype)\nprint(data1.device)\nprint(data1.layout)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.float32\ncpu\ntorch.strided\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#we can check default data type for tensor\nprint(torch.get_default_dtype())",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.float32\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#type inference for factory functions , it checks which data is coming and hence creates a dynamic object based on data type of incoming data\ndata3=torch.tensor(np.array([1,2,3]))\nprint(data3.dtype)\ndata4=torch.tensor(np.array([1.,2.,3.]))\nprint(data4.dtype)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.int64\ntorch.float64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#explicitly changing datatypes\ndata5=torch.tensor(np.array([1,2,3]),dtype=torch.float64)\nprint(data5)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([1., 2., 3.], dtype=torch.float64)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#creating tensors from numpy array by using from_numpy()\n#but torch.tensor() can be used almost for everyday.",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#different data types can't be operated upon simultaneously \ndata6=torch.tensor(np.array([1,2,3]))\ndata7=torch.tensor(np.array([1.,2.,3.]))\nprint(data6+data7) #gives error",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected object of type torch.LongTensor but found type torch.DoubleTensor for argument #3 'other'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fd536ade48f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata6\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata7\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata6\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#gives error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.LongTensor but found type torch.DoubleTensor for argument #3 'other'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(torch.eye(2)) #identity tensor by specifying no of rows\nprint(torch.zeros(2,2)) #rank -2 tensor with two axes with lenght -2\nprint(torch.randn(2,2)) #random from normal distribution with mean 0 and std deviation1 different from torch.rand() ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[1., 0.],\n        [0., 1.]])\ntensor([[0., 0.],\n        [0., 0.]])\ntensor([[-0.8258,  1.5194],\n        [ 0.7441,  2.0127]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data8=torch.randn(3,4)\nprint(data8)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[-0.3768, -0.6888, -0.7030, -0.4510],\n        [ 0.4825, -1.6580, -2.1596, -0.0955],\n        [ 0.5451, -1.2870,  2.5411,  0.9787]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#seeing the shape of the tensor as 3 rows and 4 columns with rank-2 tensor with two axes of one of length 3 and other as 4.\ndata8.shape",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "torch.Size([3, 4])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#rank of the tensor\nlen(data8.shape)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "2"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t=data8\nprint(t)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[-0.3768, -0.6888, -0.7030, -0.4510],\n        [ 0.4825, -1.6580, -2.1596, -0.0955],\n        [ 0.5451, -1.2870,  2.5411,  0.9787]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#no of elements can be found by product of each of dimensions - 3*4=12\nt.numel()",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "12"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#changing the shape of tensor by torch.view() but remeber ! we can't chnage the rank of the tensor and hecne the no of elemetns msut be same in all reshaping\nt.view(12,1)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "tensor([[-0.3768],\n        [-0.6888],\n        [-0.7030],\n        [-0.4510],\n        [ 0.4825],\n        [-1.6580],\n        [-2.1596],\n        [-0.0955],\n        [ 0.5451],\n        [-1.2870],\n        [ 2.5411],\n        [ 0.9787]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t.view(1,12)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "tensor([[-0.3768, -0.6888, -0.7030, -0.4510,  0.4825, -1.6580, -2.1596, -0.0955,\n          0.5451, -1.2870,  2.5411,  0.9787]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t.view(6,2)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "tensor([[-0.3768, -0.6888],\n        [-0.7030, -0.4510],\n        [ 0.4825, -1.6580],\n        [-2.1596, -0.0955],\n        [ 0.5451, -1.2870],\n        [ 2.5411,  0.9787]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#another way of reshaping and rank changed to rank -3 tensor\nt.view(3,2,2)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "tensor([[[-0.3768, -0.6888],\n         [-0.7030, -0.4510]],\n\n        [[ 0.4825, -1.6580],\n         [-2.1596, -0.0955]],\n\n        [[ 0.5451, -1.2870],\n         [ 2.5411,  0.9787]]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#flattening the tensor means lower its rank by 1 like here 2-d tensor lowered to 1-d tensor\nt=t.squeeze()\nprint(t)\nprint(len(t.shape))",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([-0.3768, -0.6888, -0.7030, -0.4510,  0.4825, -1.6580, -2.1596, -0.0955,\n         0.5451, -1.2870,  2.5411,  0.9787])\n1\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "#operations with dim =1 will be column wise and dim=0 will be row-wise\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "CNN IMAGE FLATTENING VISUALIZATION - "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#three images with tensors t1,t2,t3 representing pixel values (images 4x4)\nt1=torch.tensor([\n    [1,1,1,1],\n    [1,1,1,1],\n    [1,1,1,1],\n    [1,1,1,1]\n])\n\nt2=torch.tensor([\n    [2,2,2,2],\n    [2,2,2,2],\n    [2,2,2,2],\n    [2,2,2,2]\n])\n\nt3=torch.tensor([\n    [3,3,3,3],\n    [3,3,3,3],\n    [3,3,3,3],\n    [3,3,3,3]\n])\n\n#creating a batch of images for representing tensors - > (batch,colorchannel,height,width) for CNN\nt=torch.stack((t1,t2,t3))\nt=t.view(3,1,4,4)\nprint(t)",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[[[1, 1, 1, 1],\n          [1, 1, 1, 1],\n          [1, 1, 1, 1],\n          [1, 1, 1, 1]]],\n\n\n        [[[2, 2, 2, 2],\n          [2, 2, 2, 2],\n          [2, 2, 2, 2],\n          [2, 2, 2, 2]]],\n\n\n        [[[3, 3, 3, 3],\n          [3, 3, 3, 3],\n          [3, 3, 3, 3],\n          [3, 3, 3, 3]]]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#inspecting each of the axes of the t tensor for CNN\nprint(t[0])\nprint(t[0][0])\nprint(t[0][0][0])\nprint(t[0][0][0][0])",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[[1, 1, 1, 1],\n         [1, 1, 1, 1],\n         [1, 1, 1, 1],\n         [1, 1, 1, 1]]])\ntensor([[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]])\ntensor([1, 1, 1, 1])\ntensor(1)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(t.shape)",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.Size([3, 16])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t=t.flatten(start_dim=1)\nprint(t)\nprint(t.shape)",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])\ntorch.Size([3, 16])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# BROADCASTING AND ELEMENT WISE OPERATIONS - "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t1=torch.tensor([\n    [1,2],\n    [3,4]\n    \n],dtype=torch.float64)\nt2=torch.tensor([\n    [5,6],\n    [7,8]\n],dtype=torch.float64)\n\nprint(f\"hey i am {t1}\")\nprint(f\"hey i am of shape {t1.shape}\")\nprint(f\"my rank is {len(t1.shape)}\")\nprint(t2)",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": "hey i am tensor([[1., 2.],\n        [3., 4.]], dtype=torch.float64)\nhey i am of shape torch.Size([2, 2])\nmy rank is 2\ntensor([[5., 6.],\n        [7., 8.]], dtype=torch.float64)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#all arithmetic operations are element wise\nprint(t1+t2)\nprint(2*t2)\nprint(t1/2)",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[ 6.,  8.],\n        [10., 12.]], dtype=torch.float64)\ntensor([[10., 12.],\n        [14., 16.]], dtype=torch.float64)\ntensor([[0.5000, 1.0000],\n        [1.5000, 2.0000]], dtype=torch.float64)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#how t1+2 is even possible without having same shape can two tensors be operated together ? let's see-\n#the lower rank tensor is broadcasted to adjust to the higher rank dimension of tensor , to see this -\n\nnp.broadcast_to(2,t1.shape)\n",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 77,
          "data": {
            "text/plain": "array([[2, 2],\n       [2, 2]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t1+2",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 78,
          "data": {
            "text/plain": "tensor([[3., 4.],\n        [5., 6.]], dtype=torch.float64)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#under the hood broadcasting\nt1+ torch.tensor(\nnp.broadcast_to(2,t1.shape),dtype=torch.float64\n)",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 79,
          "data": {
            "text/plain": "tensor([[3., 4.],\n        [5., 6.]], dtype=torch.float64)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#another example of broadcasting where 2 is broadcasted to [2,2,2]\nt3=torch.tensor([1,2,3])\nprint(t3>2)\n",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([0, 0, 1], dtype=torch.uint8)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#yet another example of broadcasting where lower rank tensor is braocasted to the dimensions of upper rank tensor.\nt1=torch.tensor([\n    [1,2],\n    [3,4]\n])\nt2=torch.tensor([\n    [5,6]\n])\n\nprint(t1+t2)",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[ 6,  8],\n        [ 8, 10]])\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}