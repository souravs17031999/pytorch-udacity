{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# single perceptron"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch #importing torch for using pytorch ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#using sigmoid activation function for squashing the output of neural networks between 0-1 as a probability.\ndef activation(x): \n    return 1/(1+torch.exp(-x)) ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "torch.manual_seed(7) #to make sure that random numbers picked are same during each execution of program\n\nfeatures=torch.randn((1,5)) #picking random numbers from normal distribution that is a distribution which has mean 0 and stdeviation 1 of dimensions 1 row and 5 columns\nweights=torch.randn_like(features) #making sure that weight has same shape (dimensions) as features that is 1 row and 5 columns\nbias=torch.randn((1,1)) #making sure that bias is a tensor of dimensions 1 row and 1 columns so basically 1 value\nweights=weights.view(5,1) #weights change as 5 row and 1 columns so , that multiplication capability is checked \nprint(weights) #printing weights tensors\nprint(features) #printing features tensors\nprint(activation(torch.mm(features,weights)+bias)) #printing final outputs\n",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[-0.8948],\n        [-0.3556],\n        [ 1.2324],\n        [ 0.1382],\n        [-1.6822]])\ntensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\ntensor([[0.1595]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# multilayer perceptron"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "torch.manual_seed(7)\n\n# Features are 3 random normal variables\nfeatures = torch.randn((1, 3))\n# Define the size of each layer in our network\nn_input = features.shape[1]     # Number of input units, must match number of input features\nn_hidden = 2                    # Number of hidden units \nn_output = 1                    # Number of output units\n\n# Weights for inputs to hidden layer it genralizes to torch.randn(layer_before_it_units,current_layer_units)\nW1 = torch.randn(n_input, n_hidden)\n# Weights for hidden layer to output layer\nW2 = torch.randn(n_hidden, n_output)\n\n# and bias terms for hidden and output layers\nB1 = torch.randn((1, n_hidden))\nB2 = torch.randn((1, n_output))\n\nh=activation(torch.mm(features,W1)+B1)\no=activation(torch.mm(h,W2)+B2)\n\nprint(o)\n",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "tensor([[0.3171]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# numpy and pytorch"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "a=np.random.rand(4,3) #creating a random array of dimensions - 4 rows and 3 columns \na",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "array([[0.87891112, 0.18103495, 0.15642454],\n       [0.82746325, 0.49493963, 0.23733886],\n       [0.60682896, 0.18754307, 0.30518316],\n       [0.46101847, 0.90824038, 0.6861644 ]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "b=torch.from_numpy(a) #creating a pytorch tensor from numpy array\nb",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "tensor([[0.8789, 0.1810, 0.1564],\n        [0.8275, 0.4949, 0.2373],\n        [0.6068, 0.1875, 0.3052],\n        [0.4610, 0.9082, 0.6862]], dtype=torch.float64)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "c=b.numpy() #converting our tensor back to numpy\nc",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "array([[0.87891112, 0.18103495, 0.15642454],\n       [0.82746325, 0.49493963, 0.23733886],\n       [0.60682896, 0.18754307, 0.30518316],\n       [0.46101847, 0.90824038, 0.6861644 ]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "d=b.mul_(2) #multiplying our tensor by 2 to see corresponding change in our numpy array\nd",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "tensor([[3.5156, 0.7241, 0.6257],\n        [3.3099, 1.9798, 0.9494],\n        [2.4273, 0.7502, 1.2207],\n        [1.8441, 3.6330, 2.7447]], dtype=torch.float64)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "c # shows numpy arrays also change with changes made in pytorch tensors.",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "array([[3.51564449, 0.72413981, 0.62569814],\n       [3.30985301, 1.97975853, 0.94935542],\n       [2.42731585, 0.75017228, 1.22073264],\n       [1.84407387, 3.63296151, 2.7446576 ]])"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}